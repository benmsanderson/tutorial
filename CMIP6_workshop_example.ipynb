{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benmsanderson/tutorial/blob/main/CMIP6_workshop_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZdMgCDsGidf"
      },
      "source": [
        "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/benmsanderson/tutorial.git/HEAD?labpath=CMIP6_workshop_example.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibGzDNElOzhq"
      },
      "source": [
        "# CMIP6 Google cloud example for python workshop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUXOIoRvfbXn"
      },
      "source": [
        "Install xarray and the google cloud modules on the virtual machine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyVE585SCRmq"
      },
      "outputs": [],
      "source": [
        "!pip install xarray[viz] gcsfs zarr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg99d58j0JjT"
      },
      "source": [
        "\n",
        "\n",
        "Import things we'll need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aH3VEYX-Ozht"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "import zarr\n",
        "import gcsfs\n",
        "import cftime\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss9_lR75Ozhz"
      },
      "source": [
        "## Browse Catalog\n",
        "\n",
        "The data catatalog is stored as a CSV file. Here we read it with Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCXMl4MxOzh0"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv', low_memory=False)\n",
        "#let's look at the first few items\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBx9e0yoOzh4"
      },
      "source": [
        "Variables and experiments in database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63MbtACruzl0"
      },
      "outputs": [],
      "source": [
        "#make a list of variables\n",
        "vars=df.variable_id.unique()\n",
        "vars.sort()\n",
        "#Let's look for variables containing the substring 'tas'\n",
        "\n",
        "[i for i in vars if 'tas' in i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhC-x3QVr5Ys"
      },
      "outputs": [],
      "source": [
        "#make a list of unique experiments\n",
        "expts_full=df.experiment_id.unique()\n",
        "expts=pd.Series(expts_full)\n",
        "#look for all the simulations containing 'ssp5'\n",
        "expts[expts.str.contains('ssp5')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B68JehUwkmGF"
      },
      "source": [
        "Now let's find all instances of SSP5-RCP85 with surface temperature output from NorESM, note there are two model resolution versions - LM and MM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KycTNEOHDE48"
      },
      "outputs": [],
      "source": [
        "df_tmp=df[(df[\"experiment_id\"] == 'ssp585') & (df[\"variable_id\"]=='tas') & (df[\"table_id\"]=='Amon') & (df[\"source_id\"].str.contains('Nor'))]\n",
        "df_tmp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba_I8sSUOzh_"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "Load Google file system\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pgaz1EanjJ9Z"
      },
      "outputs": [],
      "source": [
        "# load Google cloud storage\n",
        "gcs = gcsfs.GCSFileSystem(token='anon')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_ppyTOjrrNy"
      },
      "source": [
        "Let's make a list of two xarray datasets, corresponding to the low and high resolution model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PEOHlp5o3c3"
      },
      "outputs": [],
      "source": [
        "#make an empty list\n",
        "dsall=[]\n",
        "#this is a loop through all of the 'zstore' values in the dataframe - which are the links to the stored data files\n",
        "for index, item in enumerate(df_tmp.zstore.values, start=0):\n",
        "        #'item' is now the zstore link\n",
        "        print('Link '+str(index)+': '+item)\n",
        "        #the mapper is the function which retrieves the link\n",
        "        mapper=gcs.get_mapper(item)\n",
        "        #now we call xarray to open the mapper and make a new dataframe\n",
        "        dstmp=xr.open_zarr(mapper)\n",
        "        #and we add this to  a list of xarray dataframes\n",
        "        dsall.append(dstmp)\n",
        "#let's print out the metadata for the first dataframe in the list\n",
        "dsall[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5BPy8Plsool"
      },
      "source": [
        "The file has one data variable so let's look at its dimensions\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOA1JwxysDFv"
      },
      "outputs": [],
      "source": [
        "dsall[0].tas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iioKP1gxs7aN"
      },
      "source": [
        "Let's plot the temperature for the last month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xz2oI11AsyhH"
      },
      "outputs": [],
      "source": [
        "dsall[0].tas[-1,:,:].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ENXQb9B0CMo"
      },
      "source": [
        "Maybe plot the zonal mean temperature..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DiLbfW5z5AT"
      },
      "outputs": [],
      "source": [
        "dsall[0].tas[-1,:,:].mean(dim='lon').plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiZVd4G_tRNt"
      },
      "source": [
        "Now let's calculate the global mean, and combine the two simulations into a single dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pgl0qhZ7tDGR"
      },
      "outputs": [],
      "source": [
        "  for i,ds in enumerate(dsall,start=0):\n",
        "    #get the latitude\n",
        "    lat=ds.tas.lat\n",
        "    #define a numpy weight vector as the cosine of latitude\n",
        "    weights = np.cos(np.deg2rad(lat))\n",
        "    #give it an attribute\n",
        "    weights.name = \"weights\"\n",
        "    #apply the weight and then average along latitude (weighted) and longitude (not weighted)\n",
        "    tmp_gm=ds.weighted(weights).mean(dim='lat').mean(dim='lon') \n",
        "    #add an ensemble dimension and label it with the name of the model\n",
        "    tmp_gm=tmp_gm.expand_dims({'ens': [ds.source_id]})\n",
        "    #now concatenate along the ensemble dimension\n",
        "    if i==0:\n",
        "        dac=tmp_gm\n",
        "    else:\n",
        "        dac=xr.concat([dac,tmp_gm],'ens')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBUhy-nzoD_l"
      },
      "source": [
        "Let's plot the annual means for the two models...  interesting, there's an offset..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IxR_w51wR3X"
      },
      "outputs": [],
      "source": [
        "dac.tas.groupby('time.year').mean().plot.line(x='year')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EHlcjRnoghY"
      },
      "source": [
        "Now let's save a new global mean netcdf to use later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUN2orjBqEe5"
      },
      "outputs": [],
      "source": [
        "dac.to_netcdf('noresm_gm.nc')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "CMIP6 workshop example.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}